{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5sum(file_path: Path) -> str:\n",
    "    \"\"\"Compute MD5 checksum for a file.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # 65536\n",
    "        # 4096\n",
    "        for chunk in iter(lambda: f.read(131072), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "# def compute_md5_parallel(file_paths: list[Path]) -> list[str]:\n",
    "#     \"\"\"Compute MD5 checksums for multiple files in parallel, with a progress bar.\"\"\"\n",
    "#     # Initialize a ProcessPoolExecutor\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         # Create a list to hold the futures\n",
    "#         futures = [executor.submit(get_md5sum, file_path) for file_path in file_paths]\n",
    "\n",
    "#         # Use tqdm to create a progress bar for the futures\n",
    "#         results = []\n",
    "#         for future in tqdm(\n",
    "#             concurrent.futures.as_completed(futures),\n",
    "#             total=len(file_paths),\n",
    "#             desc=\"Computing MD5\",\n",
    "#         ):\n",
    "#             results.append(future.result())\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMLINK_SCRNASEQ_FOLDER = Path(\n",
    "    \"/data/torsten/lara-haematopoesis-mouse/geo_upload_space/scrna_seq\"\n",
    ")\n",
    "SYMLINK_SCRNASEQ_FOLDER.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create symlinks\n",
    "\n",
    "### RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_RAW_DATA_DIR = Path(\n",
    "    \"/data/buckets/rrx-datascience-dev/torsten/lara-haematopoesis-mouse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_files = []\n",
    "for p in ROOT_RAW_DATA_DIR.rglob(\"*\"):\n",
    "    if p.is_file() and (p.suffixes == [\".fastq\", \".gz\"]):\n",
    "        fastq_files.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:03<00:00, 24.65it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_to_raw_files = {}\n",
    "parent_to_fastq = {}\n",
    "raw_md5sums = {}\n",
    "\n",
    "for p in tqdm(fastq_files):\n",
    "    stem = p.name.split(\".\", maxsplit=1)[0]\n",
    "    run_name = p.parts[-3]\n",
    "    new_name = stem + \"_\" + run_name + \".fastq.gz\"\n",
    "    if new_name.startswith(\"3\"):\n",
    "        new_name = new_name[1:]\n",
    "    new_file = Path(SYMLINK_SCRNASEQ_FOLDER / new_name)\n",
    "    if not new_file.is_file():\n",
    "        new_file.symlink_to(p)\n",
    "\n",
    "    sample = p.parts[-4]\n",
    "    sample_to_raw_files.setdefault(sample, []).append(new_file.name)\n",
    "    parent_to_fastq.setdefault(p.parent, []).append(new_file.name)\n",
    "    # this is slow:\n",
    "    # raw_md5sums[new_file.name] = get_md5sum(p)\n",
    "\n",
    "for val in parent_to_fastq.values():\n",
    "    assert len(set(val)) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PROCESSED_DATA_DIR = Path(\n",
    "    \"/data/buckets/rrx-datascience-dev/torsten/lara-haematopoesis-mouse_processed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files = []\n",
    "for p in ROOT_PROCESSED_DATA_DIR.rglob(\"*\"):\n",
    "    processed_files.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 20.90it/s]\n"
     ]
    }
   ],
   "source": [
    "parsed_md5sums = {}\n",
    "for p in tqdm(processed_files):\n",
    "    new_name = p.name\n",
    "    new_file = Path(SYMLINK_SCRNASEQ_FOLDER / new_name)\n",
    "    if not new_file.is_file():\n",
    "        new_file.symlink_to(p)\n",
    "    # parsed_md5sums[new_file.name] = get_md5sum(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GEO metadata table\n",
    "### SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = [\n",
    "    \"Activated_OP1L_NM_NA_Rep1\",\n",
    "    \"Activated_OP1L_NM_NA_Rep2\",\n",
    "    \"Quiescent_OP1L_NM_NA_Rep1\",\n",
    "    \"Quiescent_OP1L_NM_NA_Rep2\",\n",
    "    \"exVivo_OP2_IL1b_1\",\n",
    "    \"exVivo_OP2_IL1b_2\",\n",
    "    \"exVivo_OP2_resting_1\",\n",
    "    \"exVivo_OP2_resting_2\",\n",
    "    \"exVivo_OP2_TGFb_1\",\n",
    "    \"exVivo_OP2_TGFb_2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_p_files = {}\n",
    "for s in sample_names:\n",
    "    p_files = [\n",
    "        f\"{s}_filtered_feature_bc_matrix.h5\",\n",
    "        f\"{s}_protospacer_calls_per_cell.csv\",\n",
    "    ]\n",
    "    sample_to_p_files[s] = p_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.DataFrame(\n",
    "    {\n",
    "        \"*library name\": sample_names,\n",
    "        \"*title\": sample_names,\n",
    "        \"*organism\": \"Mus musculus\",\n",
    "        \"**tissue\": \"Heart\",\n",
    "        \"**cell line\": None,\n",
    "        \"**cell type\": \"Fibroblast\",\n",
    "        \"genotype\": None,\n",
    "        \"treatment\": None,\n",
    "        \"*molecule\": None,\n",
    "        \"*single or paired-end\": \"paired-end\",\n",
    "        \"*instrument model\": \"Illumina NextSeq 2000\",\n",
    "        \"description\": None,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files = pd.Series(sample_to_p_files).apply(pd.Series)\n",
    "processed_files.columns = processed_files.shape[1] * [\"*processed data file\"]\n",
    "\n",
    "raw_files = pd.Series(sample_to_raw_files).apply(pd.Series)\n",
    "raw_files.columns = raw_files.shape[1] * [\"raw file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.join(processed_files, on=\"*library name\").join(\n",
    "    raw_files, on=\"*library name\"\n",
    ")\n",
    "samples.to_excel(\"SAMPLES.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAIRED-END EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_e_exps = pd.Series(parent_to_fastq).apply(pd.Series).reset_index(drop=True)\n",
    "p_e_exps.columns = [\"file name 1\", \"file name 2\"]\n",
    "p_e_exps.to_excel(\"PAIRED_END.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MD5 check sumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(raw_md5sums, name=\"file checksum\").rename_axis(\n",
    "    \"file name\"\n",
    ").to_frame().to_excel(\"MD5_RAW_FILES.xlsx\")\n",
    "pd.Series(parsed_md5sums, name=\"file checksum\").rename_axis(\n",
    "    \"file name\"\n",
    ").to_frame().to_excel(\"MD5_PARSED_FILES.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_md5sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
